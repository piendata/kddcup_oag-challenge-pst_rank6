{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97257ad1-6ffa-4033-8071-eb34b32e3d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE, KMeansSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import shap\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "\n",
    "dir_path = '../data/PST/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "980d614f-13d8-4a91-95ac-975f013a41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle(dir_path + 'dataset_to_pred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6ad4194-f554-48a3-b3cf-c9093114a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(dir_path + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "833ef0cf-6123-4d43-9844-108b2fabeaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lgbm_clf model from ../data/PST/lgbm_clf_98_8397.pkl\n",
      "Loaded cat_clf model from ../data/PST/cat_clf_98_8397.pkl\n",
      "Loaded xgb_clf model from ../data/PST/xgb_clf_98_8397.pkl\n"
     ]
    }
   ],
   "source": [
    "def load_max_score_model(model_prefix, files):\n",
    "    pattern = re.compile(rf\"{model_prefix}_\\d+_(\\d+).pkl$\")\n",
    "    max_file = None\n",
    "    max_score = -1\n",
    "    for file in files:\n",
    "        match = pattern.search(file)\n",
    "        if match:\n",
    "            score = int(match.group(1))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_file = file\n",
    "    if max_file:\n",
    "        with open(max_file, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        print(f\"Loaded {model_prefix} model from {max_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"No {model_prefix} model files found.\")\n",
    "        return None\n",
    "\n",
    "lgbm_clf = load_max_score_model(\"lgbm_clf\", files)\n",
    "cat_clf = load_max_score_model(\"cat_clf\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f22b005-44a3-4e51-aeb2-adae227c2adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.41350902619079855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41350902619079855\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11494135705960554, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11494135705960554\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8775187936705214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8775187936705214\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6074378238140433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6074378238140433\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_proba_lgbm = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_cat = cat_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_test = (y_pred_proba_lgbm+y_pred_proba_cat)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75a07dd7-ae5d-4400-8060-3c20beb09496",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle(dir_path + 'X_test.pkl')\n",
    "df_test = pd.read_pickle(dir_path + 'df_test.pkl')\n",
    "test_index_o = pd.read_pickle(dir_path + 'test_index_o.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0b57ef9-154b-4573-ac99-ef9f36a3c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_index_o['score'] = y_test\n",
    "pred_data_test = test_index_o\n",
    "\n",
    "pred_data_test['ref_title'] = pred_data_test['ref_title'].str.lower()\n",
    "pred_data_test['ref_title'] = pred_data_test['ref_title'].str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "pred_data_test.loc[pred_data_test['score'] <= 0,'score'] = 0\n",
    "pred_data_test.loc[pred_data_test['score'] >= 1,'score'] = 1\n",
    "\n",
    "pred_data_test.to_csv(dir_path + 'pred_test.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3735f994-9e66-4328-a064-a2d4fcd55c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(dir_path + 'valid_submission_test.json', 'r') as file:\n",
    "    valid_submission_data = json.load(file)\n",
    "\n",
    "with open(dir_path + 'pred_test.csv', 'r') as file:\n",
    "    pred_data = pd.read_csv(file)\n",
    "\n",
    "pred_data['ref_title'] = pred_data['ref_title'].str.lower().str.replace(' ', '')\n",
    "\n",
    "new_valid_sub_target = {}\n",
    "\n",
    "for paper_id, entries in valid_submission_data.items():\n",
    "    new_scores = []\n",
    "    for entry in entries:\n",
    "        title = entry['title'].lower().replace(' ', '')\n",
    "        #print(title,paper_id)\n",
    "        if title:\n",
    "            score = pred_data.loc[(pred_data['_id'] == paper_id) & (pred_data['ref_title'] == title), 'score'].max()\n",
    "            if pd.isna(score):\n",
    "                score = 0 \n",
    "        else:\n",
    "            score = 0 \n",
    "        new_scores.append(score)\n",
    "    new_valid_sub_target[paper_id] = new_scores\n",
    "\n",
    "with open('new_test_sub_target.json', 'w') as file:\n",
    "    json.dump(new_valid_sub_target, file)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f831713-0f08-4f13-8ff7-9c8e90eca403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
