{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70cbdc-e7b2-4bec-bf36-c11ae4312488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from umap.umap_ import UMAP\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "import settings\n",
    "dir_path = settings.DIR_PATH\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return 1 - distance.cosine(vector1, vector2)\n",
    "\n",
    "def mahalanobis_distance(x, y, inv_cov):\n",
    "    return distance.mahalanobis(x, y, inv_cov)\n",
    "\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea216e5-1d57-4adc-8b15-dc70fd761718",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_pickle(dir_path + 'dataset_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f626c2-6d8f-4f21-a51e-68e9aaa9aee0",
   "metadata": {},
   "source": [
    "## loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c6da8-3426-4b4d-82b9-9ea19453ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer and model and send them to device\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4231dcb-2e81-4185-9425-7670cf0d1983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120ac3fa-1fce-49a3-b65e-885641a93e14",
   "metadata": {},
   "source": [
    "## abstract embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf81e9-1fb8-47f9-8e46-fa8acfbe18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df[['_id','ref_title','abstract','ref_abstract']].dropna().copy()\n",
    "df_a = df[['_id','abstract']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title','ref_abstract']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['abstract'].fillna('')\n",
    "\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['ref_abstract'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece10b16-a609-4748-8426-ffc0759e02c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "umap_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "umap_all_embeddings = umap_results[:len_all]\n",
    "umap_all_ref_embeddings = umap_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(umap_all_embeddings)\n",
    "temp.columns = ['umap_1','umap_2']\n",
    "\n",
    "df_a_umap = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_umap = pd.concat([df_a_umap,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(umap_all_ref_embeddings)\n",
    "temp.columns = ['umap_ref_1','umap_ref_2']\n",
    "\n",
    "df_b_umap = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_umap = pd.concat([df_b_umap,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_umap[['_id','umap_1','umap_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_umap[['_id','ref_title','umap_ref_1','umap_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n",
    "\n",
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "\n",
    "all_vectors = np.vstack([df_new['title_all_embeddings'].tolist(), df_new['title_all_ref_embeddings'].tolist()])\n",
    "cov_matrix = np.cov(all_vectors.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "df_new['mahalanobis_distance'] = df_new.apply(\n",
    "    lambda row: mahalanobis_distance(row['title_all_embeddings'], row['title_all_ref_embeddings'], inv_cov_matrix), axis=1\n",
    ")\n",
    "\n",
    "df_new.drop(columns = {'title_all_embeddings','title_all_ref_embeddings','abstract','ref_abstract'}).to_pickle(dir_path + 'abstract_umap_v2.pkl')\n",
    "\n",
    "df_new.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5784fe-28d0-4fd3-a36a-20db09ac75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89551bec-739b-4fd8-89fe-8d225e4898ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c68f73-918c-4f39-aa02-8f90b6cae67c",
   "metadata": {},
   "source": [
    "### title embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bdb6c-ac1b-4b09-a23a-875f002b62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = main_df[['_id','title','ref_title']].dropna().copy()\n",
    "df_a = df[['_id','title']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['title'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['ref_title'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "umap_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "umap_all_embeddings = umap_results[:len_all]\n",
    "umap_all_ref_embeddings = umap_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(umap_all_embeddings)\n",
    "temp.columns = ['umap_1','umap_2']\n",
    "\n",
    "df_a_umap = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_umap = pd.concat([df_a_umap,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(umap_all_ref_embeddings)\n",
    "temp.columns = ['umap_ref_1','umap_ref_2']\n",
    "\n",
    "df_b_umap = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_umap = pd.concat([df_b_umap,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_umap[['_id','umap_1','umap_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_umap[['_id','ref_title','umap_ref_1','umap_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n",
    "\n",
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "all_vectors = np.vstack([df_new['title_all_embeddings'].tolist(), df_new['title_all_ref_embeddings'].tolist()])\n",
    "cov_matrix = np.cov(all_vectors.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "df_new['mahalanobis_distance'] = df_new.apply(\n",
    "    lambda row: mahalanobis_distance(row['title_all_embeddings'], row['title_all_ref_embeddings'], inv_cov_matrix), axis=1\n",
    ")\n",
    "\n",
    "df_new.drop(columns = {'title','title_all_embeddings','title_all_ref_embeddings'}).to_pickle(dir_path + 'title_umap_v2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1989c-2738-44b5-8377-29ac7b711193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384f908b-f925-479e-a5ca-659e39bfe2a1",
   "metadata": {},
   "source": [
    "### context embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9a3f9-c10e-46a8-978f-6cf2848d5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df[['_id','title','ref_title','Pre Text','Post Text']].dropna().copy()\n",
    "df_a = df[['_id','ref_title','Pre Text']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title','Post Text']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['Pre Text'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['Post Text'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "umap_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "umap_all_embeddings = umap_results[:len_all]\n",
    "umap_all_ref_embeddings = umap_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(umap_all_embeddings)\n",
    "temp.columns = ['umap_1','umap_2']\n",
    "\n",
    "df_a_umap = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_umap = pd.concat([df_a_umap,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(umap_all_ref_embeddings)\n",
    "temp.columns = ['umap_ref_1','umap_ref_2']\n",
    "\n",
    "df_b_umap = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_umap = pd.concat([df_b_umap,temp2],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(umap_all_ref_embeddings)\n",
    "temp.columns = ['umap_ref_1','umap_ref_2']\n",
    "\n",
    "df_b_umap = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_umap = pd.concat([df_b_umap,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_umap[['_id','umap_1','umap_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_umap[['_id','ref_title','umap_ref_1','umap_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n",
    "\n",
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "df_new.drop(columns = {'title','title_all_embeddings','title_all_ref_embeddings'}).to_pickle(dir_path + 'context_umap.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea6722-1855-4389-baad-50d83d49b061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
