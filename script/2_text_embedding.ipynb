{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e70cbdc-e7b2-4bec-bf36-c11ae4312488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import umap\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "dir_path = '../data/PST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cf96bc4-a149-46d3-ad45-c15aff728800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    return 1 - distance.cosine(vector1, vector2)\n",
    "\n",
    "def mahalanobis_distance(x, y, inv_cov):\n",
    "    return distance.mahalanobis(x, y, inv_cov)\n",
    "\n",
    "# Function to perform average pooling\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f626c2-6d8f-4f21-a51e-68e9aaa9aee0",
   "metadata": {},
   "source": [
    "## loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "220c6da8-3426-4b4d-82b9-9ea19453ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer and model and send them to device\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ac3fa-1fce-49a3-b65e-885641a93e14",
   "metadata": {},
   "source": [
    "## abstract embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ece10b16-a609-4748-8426-ffc0759e02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 6/6 [00:58<00:00,  9.72s/it]\n",
      "Processing batches: 100%|██████████| 169/169 [29:14<00:00, 10.38s/it]\n",
      "/opt/conda/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/opt/conda/lib/python3.8/site-packages/umap/spectral.py:550: UserWarning: Spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ref_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>ref_abstract</th>\n",
       "      <th>tsne_1</th>\n",
       "      <th>tsne_2</th>\n",
       "      <th>title_all_embeddings</th>\n",
       "      <th>tsne_ref_1</th>\n",
       "      <th>tsne_ref_2</th>\n",
       "      <th>title_all_ref_embeddings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>mahalanobis_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e99792b7602d9701f57e77</td>\n",
       "      <td>a comparison of the z e 8  and leech lattices ...</td>\n",
       "      <td>the history of the theory and practice of quan...</td>\n",
       "      <td>lattice vector quantization schemes offer high...</td>\n",
       "      <td>2.701674</td>\n",
       "      <td>-1.71012</td>\n",
       "      <td>[0.26667261123657227, 0.011990290135145187, -0...</td>\n",
       "      <td>2.765877</td>\n",
       "      <td>-1.778382</td>\n",
       "      <td>[-0.24986909329891205, -0.18758516013622284, -...</td>\n",
       "      <td>0.832934</td>\n",
       "      <td>45.273721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e99792b7602d9701f57e77</td>\n",
       "      <td>a complexity reduction technique for image vec...</td>\n",
       "      <td>the history of the theory and practice of quan...</td>\n",
       "      <td>a technique for reducing the complexity of spa...</td>\n",
       "      <td>2.701674</td>\n",
       "      <td>-1.71012</td>\n",
       "      <td>[0.26667261123657227, 0.011990290135145187, -0...</td>\n",
       "      <td>2.768089</td>\n",
       "      <td>-1.824385</td>\n",
       "      <td>[-0.32262706756591797, -0.4273962378501892, -0...</td>\n",
       "      <td>0.822489</td>\n",
       "      <td>42.642719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e99792b7602d9701f57e77</td>\n",
       "      <td>a deterministic annealing approach to clustering</td>\n",
       "      <td>the history of the theory and practice of quan...</td>\n",
       "      <td></td>\n",
       "      <td>2.701674</td>\n",
       "      <td>-1.71012</td>\n",
       "      <td>[0.26667261123657227, 0.011990290135145187, -0...</td>\n",
       "      <td>9.171832</td>\n",
       "      <td>15.627504</td>\n",
       "      <td>[0.2525818645954132, -0.46831443905830383, -0....</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>28.791375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e99792b7602d9701f57e77</td>\n",
       "      <td>a direct proof of the coding theorem for discr...</td>\n",
       "      <td>the history of the theory and practice of quan...</td>\n",
       "      <td>in this paper we provide an alternate method o...</td>\n",
       "      <td>2.701674</td>\n",
       "      <td>-1.71012</td>\n",
       "      <td>[0.26667261123657227, 0.011990290135145187, -0...</td>\n",
       "      <td>2.606220</td>\n",
       "      <td>-1.652712</td>\n",
       "      <td>[0.3029211461544037, -0.571161687374115, -0.52...</td>\n",
       "      <td>0.798741</td>\n",
       "      <td>47.187264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e99792b7602d9701f57e77</td>\n",
       "      <td>a fake process approach to data compression</td>\n",
       "      <td>the history of the theory and practice of quan...</td>\n",
       "      <td>the problem of designing a good decoder for a ...</td>\n",
       "      <td>2.701674</td>\n",
       "      <td>-1.71012</td>\n",
       "      <td>[0.26667261123657227, 0.011990290135145187, -0...</td>\n",
       "      <td>2.676551</td>\n",
       "      <td>-1.768644</td>\n",
       "      <td>[0.3296864628791809, -0.305050253868103, -0.85...</td>\n",
       "      <td>0.831787</td>\n",
       "      <td>45.805418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  53e99792b7602d9701f57e77   \n",
       "1  53e99792b7602d9701f57e77   \n",
       "2  53e99792b7602d9701f57e77   \n",
       "3  53e99792b7602d9701f57e77   \n",
       "4  53e99792b7602d9701f57e77   \n",
       "\n",
       "                                           ref_title  \\\n",
       "0  a comparison of the z e 8  and leech lattices ...   \n",
       "1  a complexity reduction technique for image vec...   \n",
       "2   a deterministic annealing approach to clustering   \n",
       "3  a direct proof of the coding theorem for discr...   \n",
       "4        a fake process approach to data compression   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  the history of the theory and practice of quan...   \n",
       "1  the history of the theory and practice of quan...   \n",
       "2  the history of the theory and practice of quan...   \n",
       "3  the history of the theory and practice of quan...   \n",
       "4  the history of the theory and practice of quan...   \n",
       "\n",
       "                                        ref_abstract    tsne_1   tsne_2  \\\n",
       "0  lattice vector quantization schemes offer high...  2.701674 -1.71012   \n",
       "1  a technique for reducing the complexity of spa...  2.701674 -1.71012   \n",
       "2                                                     2.701674 -1.71012   \n",
       "3  in this paper we provide an alternate method o...  2.701674 -1.71012   \n",
       "4  the problem of designing a good decoder for a ...  2.701674 -1.71012   \n",
       "\n",
       "                                title_all_embeddings  tsne_ref_1  tsne_ref_2  \\\n",
       "0  [0.26667261123657227, 0.011990290135145187, -0...    2.765877   -1.778382   \n",
       "1  [0.26667261123657227, 0.011990290135145187, -0...    2.768089   -1.824385   \n",
       "2  [0.26667261123657227, 0.011990290135145187, -0...    9.171832   15.627504   \n",
       "3  [0.26667261123657227, 0.011990290135145187, -0...    2.606220   -1.652712   \n",
       "4  [0.26667261123657227, 0.011990290135145187, -0...    2.676551   -1.768644   \n",
       "\n",
       "                            title_all_ref_embeddings  cosine_similarity  \\\n",
       "0  [-0.24986909329891205, -0.18758516013622284, -...           0.832934   \n",
       "1  [-0.32262706756591797, -0.4273962378501892, -0...           0.822489   \n",
       "2  [0.2525818645954132, -0.46831443905830383, -0....           0.742070   \n",
       "3  [0.3029211461544037, -0.571161687374115, -0.52...           0.798741   \n",
       "4  [0.3296864628791809, -0.305050253868103, -0.85...           0.831787   \n",
       "\n",
       "   mahalanobis_distance  \n",
       "0             45.273721  \n",
       "1             42.642719  \n",
       "2             28.791375  \n",
       "3             47.187264  \n",
       "4             45.805418  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(dir_path + 'dataset_v2.pkl')\n",
    "\n",
    "df = df[['_id','ref_title','abstract','ref_abstract']].dropna().copy()\n",
    "df_a = df[['_id','abstract']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title','ref_abstract']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['abstract'].fillna('')\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 1000  # Adjust based on your memory capacity\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['ref_abstract'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "tsne_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "tsne_all_embeddings = tsne_results[:len_all]\n",
    "tsne_all_ref_embeddings = tsne_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_embeddings)\n",
    "temp.columns = ['tsne_1','tsne_2']\n",
    "\n",
    "df_a_tsne = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_tsne = pd.concat([df_a_tsne,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_ref_embeddings)\n",
    "temp.columns = ['tsne_ref_1','tsne_ref_2']\n",
    "\n",
    "df_b_tsne = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_tsne = pd.concat([df_b_tsne,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_tsne[['_id','tsne_1','tsne_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_tsne[['_id','ref_title','tsne_ref_1','tsne_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n",
    "\n",
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "\n",
    "all_vectors = np.vstack([df_new['title_all_embeddings'].tolist(), df_new['title_all_ref_embeddings'].tolist()])\n",
    "cov_matrix = np.cov(all_vectors.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "df_new['mahalanobis_distance'] = df_new.apply(\n",
    "    lambda row: mahalanobis_distance(row['title_all_embeddings'], row['title_all_ref_embeddings'], inv_cov_matrix), axis=1\n",
    ")\n",
    "\n",
    "df_new.drop(columns = {'title_all_embeddings','title_all_ref_embeddings','abstract','ref_abstract'}).to_pickle(dir_path + 'abstract_tsne_v2.pkl')\n",
    "\n",
    "df_new.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c49d2-cd65-4b04-b01a-fb904159eed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c68f73-918c-4f39-aa02-8f90b6cae67c",
   "metadata": {},
   "source": [
    "### title embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9bdb6c-ac1b-4b09-a23a-875f002b62b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 6/6 [00:08<00:00,  1.42s/it]\n",
      "Processing batches: 100%|██████████| 230/230 [08:32<00:00,  2.23s/it]\n",
      "/opt/conda/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(dir_path + 'dataset_v2.pkl')\n",
    "\n",
    "df = df[['_id','title','ref_title']].dropna().copy()\n",
    "df_a = df[['_id','title']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['title'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['ref_title'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "tsne_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "tsne_all_embeddings = tsne_results[:len_all]\n",
    "tsne_all_ref_embeddings = tsne_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_embeddings)\n",
    "temp.columns = ['tsne_1','tsne_2']\n",
    "\n",
    "df_a_tsne = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_tsne = pd.concat([df_a_tsne,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_ref_embeddings)\n",
    "temp.columns = ['tsne_ref_1','tsne_ref_2']\n",
    "\n",
    "df_b_tsne = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_tsne = pd.concat([df_b_tsne,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_tsne[['_id','tsne_1','tsne_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_tsne[['_id','ref_title','tsne_ref_1','tsne_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n",
    "\n",
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "all_vectors = np.vstack([df_new['title_all_embeddings'].tolist(), df_new['title_all_ref_embeddings'].tolist()])\n",
    "cov_matrix = np.cov(all_vectors.T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "df_new['mahalanobis_distance'] = df_new.apply(\n",
    "    lambda row: mahalanobis_distance(row['title_all_embeddings'], row['title_all_ref_embeddings'], inv_cov_matrix), axis=1\n",
    ")\n",
    "\n",
    "df_new.drop(columns = {'title','title_all_embeddings','title_all_ref_embeddings'}).to_pickle(dir_path + 'title_tsne_v2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2ed60-50a4-461f-bd24-63a6cbeb857f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384f908b-f925-479e-a5ca-659e39bfe2a1",
   "metadata": {},
   "source": [
    "### context embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6725c41-424d-44bc-91ce-88de691296d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc9a3f9-c10e-46a8-978f-6cf2848d5e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 223/223 [25:50<00:00,  6.95s/it]\n",
      "Processing batches: 100%|██████████| 223/223 [24:36<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(dir_path + 'dataset_v2.pkl')\n",
    "df = df[['_id','title','ref_title','Pre Text','Post Text']].dropna().copy()\n",
    "df_a = df[['_id','ref_title','Pre Text']].drop_duplicates()\n",
    "df_b = df[['_id','ref_title','Post Text']].drop_duplicates()\n",
    "\n",
    "abstracts = df_a['Pre Text'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_embeddings = np.vstack(embeddings)\n",
    "\n",
    "abstracts = df_b['Post Text'].fillna('')\n",
    "\n",
    "# Process in batches\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(abstracts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_abstracts = abstracts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_abstracts, max_length=256, padding=True, truncation=True, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Send input to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())  # Move embeddings back to CPU\n",
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3303d-6b8d-4067-b5c7-562fed18c64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abaee27-a61d-4cb5-90d7-915724b8b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Concatenate all batch embeddings\n",
    "all_ref_embeddings = np.vstack(embeddings)\n",
    "\n",
    "labels = np.array(['original'] * len(all_embeddings) + ['reference'] * len(all_ref_embeddings))\n",
    "\n",
    "combined_embeddings = np.concatenate([all_embeddings, all_ref_embeddings])\n",
    "\n",
    "# UMAP instance creation with n_neighbors and min_dist as optional parameters\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP on the combined embeddings\n",
    "tsne_results = umap_reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_embeddings]\n",
    "temp1 = pd.DataFrame(list_of_lists, columns=['title_all_embeddings'])\n",
    "\n",
    "list_of_lists = [[row.tolist()] for row in all_ref_embeddings]\n",
    "temp2 = pd.DataFrame(list_of_lists, columns=['title_all_ref_embeddings'])\n",
    "\n",
    "len_all = len(all_embeddings)\n",
    "len_ref = len(all_ref_embeddings)\n",
    "\n",
    "tsne_all_embeddings = tsne_results[:len_all]\n",
    "tsne_all_ref_embeddings = tsne_results[len_all:len_all + len_ref]\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_embeddings)\n",
    "temp.columns = ['tsne_1','tsne_2']\n",
    "\n",
    "df_a_tsne = pd.concat([df_a.reset_index(drop = True),temp],axis = 1)\n",
    "df_a_tsne = pd.concat([df_a_tsne,temp1],axis = 1)\n",
    "\n",
    "temp = pd.DataFrame(tsne_all_ref_embeddings)\n",
    "temp.columns = ['tsne_ref_1','tsne_ref_2']\n",
    "\n",
    "df_b_tsne = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_tsne = pd.concat([df_b_tsne,temp2],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5518edde-7a5e-4403-9b0d-f2d6fd6fe361",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(tsne_all_ref_embeddings)\n",
    "temp.columns = ['tsne_ref_1','tsne_ref_2']\n",
    "\n",
    "df_b_tsne = pd.concat([df_b.reset_index(drop = True),temp],axis = 1)\n",
    "df_b_tsne = pd.concat([df_b_tsne,temp2],axis = 1)\n",
    "\n",
    "df_new = df.merge(df_a_tsne[['_id','tsne_1','tsne_2','title_all_embeddings']], on = ['_id'],how = 'left')\n",
    "df_new = df_new.merge(df_b_tsne[['_id','ref_title','tsne_ref_1','tsne_ref_2','title_all_ref_embeddings']], on = ['_id','ref_title'],how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2da77c6-f533-4cd9-a1fb-e8d79a8a6ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'title', 'ref_title', 'Pre Text', 'Post Text', 'tsne_1',\n",
       "       'tsne_2', 'title_all_embeddings', 'tsne_ref_1', 'tsne_ref_2',\n",
       "       'title_all_ref_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e236249-cf9c-492a-b31b-32177eed0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new['cosine_similarity'] = df_new.apply(\n",
    "    lambda row: cosine_similarity(row['title_all_embeddings'], row['title_all_ref_embeddings']), axis=1\n",
    ")\n",
    "df_new.drop(columns = {'title','title_all_embeddings','title_all_ref_embeddings'}).to_pickle(dir_path + 'context_tsne.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd1f98e-6e9c-4619-88d8-a915186f0d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'title', 'ref_title', 'Pre Text', 'Post Text', 'tsne_1',\n",
       "       'tsne_2', 'title_all_embeddings', 'tsne_ref_1', 'tsne_ref_2',\n",
       "       'title_all_ref_embeddings', 'cosine_similarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea6722-1855-4389-baad-50d83d49b061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
