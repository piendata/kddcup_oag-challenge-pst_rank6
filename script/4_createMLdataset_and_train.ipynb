{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97257ad1-6ffa-4033-8071-eb34b32e3d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc  \n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE, KMeansSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import shap\n",
    "\n",
    "import pickle\n",
    "\n",
    "dir_path = '../data/PST/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9c1b18-e354-4bf9-888e-880a9ea83775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dir_path + 'dataset_v2.pkl')\n",
    "\n",
    "check = df.loc[(df['target'] == 1)\n",
    "               & (~df['ref_title'].isna())\n",
    "            & (df['citation_cnt'].isna())]\n",
    "\n",
    "tempolary_xml = pd.read_pickle(dir_path + 'tempolary_xml.pkl')\n",
    "tempolary_xml_ref = pd.read_pickle(dir_path + 'tempolary_xml.pkl')\n",
    "\n",
    "df = df.merge(tempolary_xml[['_id','title','abstract']],how = 'left',on = '_id')\n",
    "\n",
    "df['title'] = df.apply(lambda x: x['title_x'] if pd.notna(x['title_x']) else x['title_y'], axis=1)\n",
    "\n",
    "df.drop(columns=['title_x', 'title_y'], inplace=True)\n",
    "\n",
    "df['abstract'] = df.apply(lambda x: x['abstract_x'] if pd.notna(x['abstract_x']) else x['abstract_y'], axis=1)\n",
    "\n",
    "df.drop(columns=['abstract_x', 'abstract_y'], inplace=True)\n",
    "\n",
    "df['title'] = df['title'].str.replace('\\n', '', regex=False)\n",
    "df['ref_title'] = df['ref_title'].str.replace('\\n', '', regex=False)\n",
    "df['abstract'] = df['abstract'].str.replace('\\n', '', regex=False)\n",
    "df['ref_abstract'] = df['ref_abstract'].str.replace('\\n', '', regex=False)\n",
    "\n",
    "df['abstract'] = df['abstract'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['ref_abstract'] = df['ref_abstract'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['ref_title'] = df['ref_title'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['title'] = df['title'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "def set_flags(df, column, flags):\n",
    "    for flag, substr in flags.items():\n",
    "        df[flag] = np.where(df[column].str.contains(substr, case=False, na=False), 1, 0)\n",
    "\n",
    "flags = {\n",
    "    'IEEE_flg': 'ieee',\n",
    "    'acm_flg': 'acm',\n",
    "    'cvpr_flg': 'cvpr',\n",
    "    'nips_flg': 'nips',\n",
    "    'Econometrica_flg':'econometrica',\n",
    "    'KDD_flg':'kdd'\n",
    "}\n",
    "\n",
    "set_flags(df, 'venue', flags)\n",
    "set_flags(df, 'ref_venue', {f'ref_{k}': v for k, v in flags.items()})\n",
    "\n",
    "df['Section'] = df['Section'].fillna('')\n",
    "df['Pre Text'] = df['Pre Text'].fillna('')\n",
    "df['Post Text'] = df['Post Text'].fillna('')\n",
    "\n",
    "\n",
    "def set_text_flags(df, columns, patterns):\n",
    "    for col, flags in patterns.items():\n",
    "        for flag, substr in flags.items():\n",
    "            df[flag] = np.where(df[col].str.contains(substr, case=False, na=False), 1, 0)\n",
    "\n",
    "text_patterns = {\n",
    "    'Pre Text': {\n",
    "        'important_flg': 'important',\n",
    "        'motiva_flg': 'motiva',\n",
    "        'most_flg': ' most ',\n",
    "        'impact_flg': 'impact',\n",
    "        'based_flg': 'based'\n",
    "    },\n",
    "    'Post Text': {\n",
    "        'important_flg': 'important',\n",
    "        'motiva_flg': 'motiva',\n",
    "        'most_flg': ' most ',\n",
    "        'impact_flg': 'impact',\n",
    "        'based_flg': 'based'\n",
    "    },\n",
    "    'Section': {\n",
    "        'conclusion_flg': 'conclusion',\n",
    "        'intro_flg': 'intro',\n",
    "        'material_flg': 'material',\n",
    "        'method_flg': 'method',\n",
    "        'result_flg': 'result',\n",
    "        'discussion_flg': 'discussion',\n",
    "        'abstract_flg': 'abstract'\n",
    "    }\n",
    "}\n",
    "\n",
    "set_text_flags(df, text_patterns.keys(), text_patterns)\n",
    "\n",
    "\n",
    "valid_index_o = df.loc[df['train_or_valid'] == 'valid'][['_id','ref_title']].copy()\n",
    "test_index_o = df.loc[df['train_or_valid'] == 'test'][['_id','ref_title']].copy()\n",
    "\n",
    "venue_impact = pd.read_pickle(dir_path + 'venue_impact_v2.pkl')\n",
    "venue_impact.columns = ['venue','v_n_citation']\n",
    "\n",
    "dblp_feature = pd.read_pickle(dir_path + 'dblp_feature_v2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4ff6f-fe88-4b21-aae1-9362832bb820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b57bf31-d94f-4fef-a20c-3c2cf7992fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304353\n"
     ]
    }
   ],
   "source": [
    "node2vec = pd.read_csv(dir_path + 'node2vec_umap_v3.csv.gz',compression='gzip')\n",
    "#node2vec = pd.read_csv('./pst_node2vec_umap.csv.gz',compression='gzip')\n",
    "node2vec = node2vec[['UMAP1','UMAP2','node_id']].rename(columns = {'node_id':'_id'})\n",
    "df = df.merge(node2vec, on = '_id', how = 'left')\n",
    "node2vec = node2vec[['UMAP1','UMAP2','_id']].rename(columns = {'_id':'ref_id'})\n",
    "df = df.merge(node2vec, on = 'ref_id', how = 'left')\n",
    "\n",
    "author_citation = pd.read_pickle(dir_path + 'author_citation_v2.pkl')\n",
    "\n",
    "author_citation.columns = ['_id','author_citation']\n",
    "dblp_feature.columns = ['_id','in_citation_count','page_count']\n",
    "df = df.merge(author_citation,on = '_id',how = 'left')\n",
    "\n",
    "dblp_feature = dblp_feature.groupby('_id').sum().reset_index()\n",
    "\n",
    "#df = df.merge(co_author,on = ['_id','ref_id'],how = 'left')\n",
    "print(len(df))\n",
    "df = df.merge(dblp_feature,on = ['_id'],how = 'left')\n",
    "\n",
    "\n",
    "df.loc[df['Citation Number'] == 'Unknown', 'Citation Number'] = np.nan \n",
    "\n",
    "df['citation_cnt'] = df.groupby('_id')['citation_cnt'].transform(lambda x: x.fillna(x.median()))\n",
    "df['Citation Number'] = df.groupby('_id')['Citation Number'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df.loc[df['Citation Number'] == 'Unknown','Citation Number'] = 99\n",
    "df['Citation Number'] = df['Citation Number'].fillna(99)\n",
    "df['Citation Number'] = df['Citation Number'].astype(int)\n",
    "df.loc[df['Citation Number'] >= 99,'Citation Number'] = 99\n",
    "df.loc[df['Citation Number'] < 1,'Citation Number'] = 99\n",
    "\n",
    "max_cinum = df[['Citation Number','_id']].loc[df['Citation Number'] != 999].groupby('_id').max().reset_index()\n",
    "max_cinum.columns = ['_id','max_citation_num']\n",
    "\n",
    "df = df.merge(max_cinum,how = 'left',on = '_id')\n",
    "\n",
    "df['Citation_Ration'] = df['Citation Number']/df['max_citation_num']\n",
    "\n",
    "train_index_o = pd.concat([df[(df['target'] == 1)],# & (df.annotation_ref.isna())],\n",
    "              df[(df['train_or_valid'] == 'train') & (df['target'] == 0)].sample(n = 7000,random_state= 42)])\n",
    "train_index_o.to_csv('train_index.csv',index = False)\n",
    "\n",
    "df['diff_year'] = df['year'] - df['ref_year']\n",
    "df['n_citation'] = df['n_citation'].apply(lambda x: x + 0.001)\n",
    "df['ref_n_citation'] = df['ref_n_citation'].apply(lambda x: x + 0.001)\n",
    "df['diff_year'] = df['diff_year'].apply(lambda x: x + 0.001)\n",
    "\n",
    "df.loc[df['diff_year'] <= 0, 'diff_year'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1d01fb-5db6-472a-a4c5-868f15d307db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304353\n",
      "304353\n",
      "304353\n"
     ]
    }
   ],
   "source": [
    "tsne_title = pd.read_pickle(dir_path + 'title_tsne_v2.pkl')\n",
    "tsne_abstract = pd.read_pickle(dir_path + 'abstract_tsne_v2.pkl')\n",
    "\n",
    "tsne_title = tsne_title.rename(columns = {'tsne_1':'tsne_1_title','tsne_2':'tsne_2_title'})\n",
    "tsne_abstract = tsne_abstract.rename(columns = {'tsne_1':'tsne_1_abstract','tsne_2':'tsne_2_abstract'})\n",
    "\n",
    "tsne_title = tsne_title.groupby(['_id','ref_title']).mean().reset_index()\n",
    "tsne_abstract = tsne_abstract.groupby(['_id','ref_title']).mean().reset_index()\n",
    "\n",
    "print(len(df))\n",
    "df = df.merge(tsne_title,on = ['_id','ref_title'],how = 'left')\n",
    "df = df.merge(tsne_abstract,on = ['_id','ref_title'],how = 'left')\n",
    "print(len(df))\n",
    "\n",
    "tsne_context = pd.read_pickle(dir_path + 'context_tsne.pkl')\n",
    "\n",
    "tsne_context = tsne_context.rename(columns = {'tsne_1':'tsne_1_context','tsne_2':'tsne_2_context'})\n",
    "tsne_context = tsne_context.drop(columns = {'Pre Text','Post Text'}).groupby(['_id','ref_title']).mean().reset_index()\n",
    "df = df.merge(tsne_context,on = ['_id','ref_title'],how = 'left')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ff4bdf-5925-4d7a-852f-e233862095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp = df[['citation_cnt', 'Citation Number',\n",
    "           'ref_n_citation', 'n_citation',\n",
    "           'train_or_valid', 'target',\n",
    "           'IEEE_flg', 'acm_flg', 'cvpr_flg', 'nips_flg',\n",
    "           'Econometrica_flg', 'KDD_flg', 'ref_IEEE_flg', 'ref_acm_flg',\n",
    "           'ref_cvpr_flg', 'ref_nips_flg', 'ref_Econometrica_flg', 'ref_KDD_flg',\n",
    "           'important_flg', 'motiva_flg', 'most_flg', 'impact_flg', 'based_flg',\n",
    "           'conclusion_flg', 'intro_flg', 'material_flg', 'method_flg',\n",
    "           'result_flg', 'discussion_flg', 'abstract_flg', \n",
    "            'UMAP1_x', 'UMAP2_x',\n",
    "              'UMAP1_y', 'UMAP2_y',\n",
    "           'author_citation',\n",
    "           'in_citation_count', 'page_count', 'max_citation_num',\n",
    "           'Citation_Ration', 'diff_year', 'tsne_2_title',\n",
    "           'tsne_ref_1_x', 'tsne_ref_2_x', 'cosine_similarity_x',\n",
    "           'mahalanobis_distance_x', 'tsne_1_abstract', 'tsne_2_abstract',\n",
    "           'tsne_ref_1_y', 'tsne_ref_2_y', 'cosine_similarity_y',\n",
    "           'mahalanobis_distance_y', 'tsne_1_context', 'tsne_2_context',\n",
    "           'tsne_ref_1', 'tsne_ref_2'\n",
    "             ]].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f07e-b9c1-40ea-accf-c0e0edd432e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-06-13 10:32:24,544]\u001b[0m A new study created in memory with name: no-name-aa5ae1df-18a4-471f-a18f-789a574b4603\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borderline-SMOTE resampled data shape: (1552, 53) (1552,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-06-13 10:32:24,778]\u001b[0m Trial 0 finished with value: 0.8432469775474957 and parameters: {'lambda_l1': 0.7090546075522169, 'lambda_l2': 0.09217335256236983, 'num_leaves': 274, 'feature_fraction': 0.3924726573980598, 'bagging_fraction': 0.5572068820808586, 'bagging_freq': 2, 'min_child_samples': 107}. Best is trial 0 with value: 0.8432469775474957.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:25,102]\u001b[0m Trial 1 finished with value: 0.8393436960276339 and parameters: {'lambda_l1': 0.8034497824857166, 'lambda_l2': 0.10248990048174987, 'num_leaves': 177, 'feature_fraction': 0.41144384648879734, 'bagging_fraction': 0.600506580492696, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 0 with value: 0.8432469775474957.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:25,480]\u001b[0m Trial 2 finished with value: 0.8401381692573403 and parameters: {'lambda_l1': 1.04338254799344, 'lambda_l2': 0.13143925834305195, 'num_leaves': 193, 'feature_fraction': 0.5158796632879227, 'bagging_fraction': 0.6453902933034852, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 0 with value: 0.8432469775474957.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:25,784]\u001b[0m Trial 3 finished with value: 0.8381347150259068 and parameters: {'lambda_l1': 0.9850922835199754, 'lambda_l2': 0.16683293004611743, 'num_leaves': 170, 'feature_fraction': 0.47734907233552715, 'bagging_fraction': 0.5588680539681105, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 0 with value: 0.8432469775474957.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:26,096]\u001b[0m Trial 4 finished with value: 0.8352331606217617 and parameters: {'lambda_l1': 0.7694434086628491, 'lambda_l2': 0.16560883854787223, 'num_leaves': 177, 'feature_fraction': 0.39018287234648275, 'bagging_fraction': 0.5569049571342515, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 0 with value: 0.8432469775474957.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:26,349]\u001b[0m Trial 5 finished with value: 0.8433160621761658 and parameters: {'lambda_l1': 1.0921054286312204, 'lambda_l2': 0.14044819104077455, 'num_leaves': 255, 'feature_fraction': 0.3905598511721232, 'bagging_fraction': 0.6707086124547819, 'bagging_freq': 2, 'min_child_samples': 108}. Best is trial 5 with value: 0.8433160621761658.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:26,586]\u001b[0m Trial 6 finished with value: 0.8425561312607944 and parameters: {'lambda_l1': 0.9530993570768788, 'lambda_l2': 0.13762019431061612, 'num_leaves': 259, 'feature_fraction': 0.4681112213010645, 'bagging_fraction': 0.5872214073739364, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 5 with value: 0.8433160621761658.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:26,980]\u001b[0m Trial 7 finished with value: 0.8492918825561313 and parameters: {'lambda_l1': 1.0675651818606053, 'lambda_l2': 0.11538203770850328, 'num_leaves': 205, 'feature_fraction': 0.3641136756576417, 'bagging_fraction': 0.6549605436772903, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:27,259]\u001b[0m Trial 8 finished with value: 0.8396891191709843 and parameters: {'lambda_l1': 0.8043637547382989, 'lambda_l2': 0.11958723410099163, 'num_leaves': 305, 'feature_fraction': 0.4824621353806242, 'bagging_fraction': 0.5952439386127258, 'bagging_freq': 2, 'min_child_samples': 93}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:27,478]\u001b[0m Trial 9 finished with value: 0.8441796200345423 and parameters: {'lambda_l1': 0.7481982959737125, 'lambda_l2': 0.13315563270779734, 'num_leaves': 346, 'feature_fraction': 0.5438839200495342, 'bagging_fraction': 0.5710546062723594, 'bagging_freq': 2, 'min_child_samples': 103}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:27,690]\u001b[0m Trial 10 finished with value: 0.8375129533678756 and parameters: {'lambda_l1': 0.8930964392868452, 'lambda_l2': 0.11291894596121763, 'num_leaves': 213, 'feature_fraction': 0.3549737654516416, 'bagging_fraction': 0.6999332028811964, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:27,893]\u001b[0m Trial 11 finished with value: 0.844041450777202 and parameters: {'lambda_l1': 0.8774628315015223, 'lambda_l2': 0.15204526990101644, 'num_leaves': 346, 'feature_fraction': 0.5385137348801439, 'bagging_fraction': 0.6436075583788061, 'bagging_freq': 2, 'min_child_samples': 102}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:28,201]\u001b[0m Trial 12 finished with value: 0.8378238341968913 and parameters: {'lambda_l1': 0.7062213411802092, 'lambda_l2': 0.11935024138785734, 'num_leaves': 218, 'feature_fraction': 0.3515299869464576, 'bagging_fraction': 0.6807356914606731, 'bagging_freq': 2, 'min_child_samples': 102}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:28,503]\u001b[0m Trial 13 finished with value: 0.8367184801381692 and parameters: {'lambda_l1': 1.088053342467214, 'lambda_l2': 0.10409896851520227, 'num_leaves': 345, 'feature_fraction': 0.4322425293429686, 'bagging_fraction': 0.6291109861614694, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:28,785]\u001b[0m Trial 14 finished with value: 0.8394473229706391 and parameters: {'lambda_l1': 0.994075491574438, 'lambda_l2': 0.14827173611265015, 'num_leaves': 307, 'feature_fraction': 0.5146320317883132, 'bagging_fraction': 0.6728937903667138, 'bagging_freq': 2, 'min_child_samples': 103}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:29,074]\u001b[0m Trial 15 finished with value: 0.8428670120898101 and parameters: {'lambda_l1': 0.846348350516922, 'lambda_l2': 0.12446538941721945, 'num_leaves': 226, 'feature_fraction': 0.4411984169905199, 'bagging_fraction': 0.6176600312622557, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:29,346]\u001b[0m Trial 16 finished with value: 0.8454576856649396 and parameters: {'lambda_l1': 0.9391846707672806, 'lambda_l2': 0.10762715657391014, 'num_leaves': 153, 'feature_fraction': 0.5084486288796513, 'bagging_fraction': 0.5771950963281273, 'bagging_freq': 2, 'min_child_samples': 98}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:29,580]\u001b[0m Trial 17 finished with value: 0.8420379965457686 and parameters: {'lambda_l1': 0.9368496618648833, 'lambda_l2': 0.0920258063190004, 'num_leaves': 157, 'feature_fraction': 0.5066823494640561, 'bagging_fraction': 0.6557829593221258, 'bagging_freq': 2, 'min_child_samples': 91}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:29,963]\u001b[0m Trial 18 finished with value: 0.8394818652849741 and parameters: {'lambda_l1': 1.0417275290327839, 'lambda_l2': 0.10709876120970135, 'num_leaves': 199, 'feature_fraction': 0.4572170477175659, 'bagging_fraction': 0.6179265852987813, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:30,247]\u001b[0m Trial 19 finished with value: 0.8425561312607945 and parameters: {'lambda_l1': 1.0404929843065054, 'lambda_l2': 0.09647995696752625, 'num_leaves': 159, 'feature_fraction': 0.4974615296456195, 'bagging_fraction': 0.6967800956348157, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 7 with value: 0.8492918825561313.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:30,497]\u001b[0m Trial 20 finished with value: 0.8530915371329878 and parameters: {'lambda_l1': 0.9517751242041296, 'lambda_l2': 0.11027960119334455, 'num_leaves': 151, 'feature_fraction': 0.3671829472931868, 'bagging_fraction': 0.57962136639343, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 20 with value: 0.8530915371329878.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:30,792]\u001b[0m Trial 21 finished with value: 0.8478411053540588 and parameters: {'lambda_l1': 0.9248674351314959, 'lambda_l2': 0.11288717051766309, 'num_leaves': 158, 'feature_fraction': 0.36951753798818626, 'bagging_fraction': 0.5771300576437883, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 20 with value: 0.8530915371329878.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:31,055]\u001b[0m Trial 22 finished with value: 0.8543696027633851 and parameters: {'lambda_l1': 0.9859941184058264, 'lambda_l2': 0.11428306865060746, 'num_leaves': 194, 'feature_fraction': 0.36658449641795077, 'bagging_fraction': 0.5751550797594793, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:31,276]\u001b[0m Trial 23 finished with value: 0.8425906735751295 and parameters: {'lambda_l1': 0.9987904454962053, 'lambda_l2': 0.12375368522971149, 'num_leaves': 238, 'feature_fraction': 0.3700765964163733, 'bagging_fraction': 0.6294186728193435, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:31,599]\u001b[0m Trial 24 finished with value: 0.8513298791019 and parameters: {'lambda_l1': 1.0646845097816882, 'lambda_l2': 0.11482845968287143, 'num_leaves': 197, 'feature_fraction': 0.3712742044424784, 'bagging_fraction': 0.6056347519423786, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:31,843]\u001b[0m Trial 25 finished with value: 0.8407944732297065 and parameters: {'lambda_l1': 1.000238590807453, 'lambda_l2': 0.09953256936195463, 'num_leaves': 188, 'feature_fraction': 0.4127496319526469, 'bagging_fraction': 0.6049560552923003, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:32,054]\u001b[0m Trial 26 finished with value: 0.8486701208981002 and parameters: {'lambda_l1': 0.9691355438456635, 'lambda_l2': 0.1100596220982906, 'num_leaves': 231, 'feature_fraction': 0.3802561035323264, 'bagging_fraction': 0.5902689093343689, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:32,350]\u001b[0m Trial 27 finished with value: 0.8423143350604491 and parameters: {'lambda_l1': 1.0206794186491035, 'lambda_l2': 0.1275602240457191, 'num_leaves': 186, 'feature_fraction': 0.4119062038282753, 'bagging_fraction': 0.6088438256608726, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:32,599]\u001b[0m Trial 28 finished with value: 0.8390673575129534 and parameters: {'lambda_l1': 1.0672750240213176, 'lambda_l2': 0.11957988713370978, 'num_leaves': 171, 'feature_fraction': 0.3507102995103657, 'bagging_fraction': 0.5663400247673471, 'bagging_freq': 2, 'min_child_samples': 93}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:32,871]\u001b[0m Trial 29 finished with value: 0.8479447322970639 and parameters: {'lambda_l1': 0.9102550431166189, 'lambda_l2': 0.09618474702344751, 'num_leaves': 276, 'feature_fraction': 0.40158229047606386, 'bagging_fraction': 0.5837049163712493, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:33,161]\u001b[0m Trial 30 finished with value: 0.839378238341969 and parameters: {'lambda_l1': 0.8649265439654401, 'lambda_l2': 0.11579974601618814, 'num_leaves': 242, 'feature_fraction': 0.42709842472764625, 'bagging_fraction': 0.6109017988398785, 'bagging_freq': 1, 'min_child_samples': 106}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:33,372]\u001b[0m Trial 31 finished with value: 0.8433506044905009 and parameters: {'lambda_l1': 1.078342895126795, 'lambda_l2': 0.11531760032012954, 'num_leaves': 208, 'feature_fraction': 0.365538326167439, 'bagging_fraction': 0.5514599006954104, 'bagging_freq': 2, 'min_child_samples': 91}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:33,660]\u001b[0m Trial 32 finished with value: 0.8477720207253886 and parameters: {'lambda_l1': 1.0605418714974164, 'lambda_l2': 0.10866384062876376, 'num_leaves': 202, 'feature_fraction': 0.3812519070243479, 'bagging_fraction': 0.6393855697890434, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:34,082]\u001b[0m Trial 33 finished with value: 0.8496027633851468 and parameters: {'lambda_l1': 0.9719135937918293, 'lambda_l2': 0.10188839475084085, 'num_leaves': 182, 'feature_fraction': 0.36211993664552256, 'bagging_fraction': 0.6564615238463113, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:34,393]\u001b[0m Trial 34 finished with value: 0.8443523316062176 and parameters: {'lambda_l1': 0.9675166361350237, 'lambda_l2': 0.10137583530845276, 'num_leaves': 180, 'feature_fraction': 0.37910101126433277, 'bagging_fraction': 0.5998694828949458, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:34,769]\u001b[0m Trial 35 finished with value: 0.8417616580310882 and parameters: {'lambda_l1': 1.025621521439429, 'lambda_l2': 0.09719765555991146, 'num_leaves': 164, 'feature_fraction': 0.35052256614234417, 'bagging_fraction': 0.5618358669909285, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:35,054]\u001b[0m Trial 36 finished with value: 0.8449050086355785 and parameters: {'lambda_l1': 0.9741405678793952, 'lambda_l2': 0.09070158311366672, 'num_leaves': 150, 'feature_fraction': 0.3985031121267433, 'bagging_fraction': 0.5951471781043832, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:35,278]\u001b[0m Trial 37 finished with value: 0.8429015544041452 and parameters: {'lambda_l1': 1.021336731838799, 'lambda_l2': 0.10352757727808631, 'num_leaves': 193, 'feature_fraction': 0.36105677237686423, 'bagging_fraction': 0.5772212187060761, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:35,498]\u001b[0m Trial 38 finished with value: 0.8324352331606217 and parameters: {'lambda_l1': 0.9503224119135846, 'lambda_l2': 0.12323323827382912, 'num_leaves': 173, 'feature_fraction': 0.3891026461965242, 'bagging_fraction': 0.5838566591821821, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:35,780]\u001b[0m Trial 39 finished with value: 0.8390328151986184 and parameters: {'lambda_l1': 0.9046009486663322, 'lambda_l2': 0.10477917861405629, 'num_leaves': 219, 'feature_fraction': 0.3763273861632034, 'bagging_fraction': 0.5525643792724279, 'bagging_freq': 2, 'min_child_samples': 83}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:36,063]\u001b[0m Trial 40 finished with value: 0.8441450777202072 and parameters: {'lambda_l1': 0.9809429157684979, 'lambda_l2': 0.13294174041933043, 'num_leaves': 186, 'feature_fraction': 0.4021812078608397, 'bagging_fraction': 0.6558423839372796, 'bagging_freq': 2, 'min_child_samples': 96}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:36,299]\u001b[0m Trial 41 finished with value: 0.8448704663212435 and parameters: {'lambda_l1': 1.061770069745852, 'lambda_l2': 0.1123996956374755, 'num_leaves': 202, 'feature_fraction': 0.36194272634774055, 'bagging_fraction': 0.6588706759423552, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:36,578]\u001b[0m Trial 42 finished with value: 0.8459412780656304 and parameters: {'lambda_l1': 1.005230519448733, 'lambda_l2': 0.11649203978767786, 'num_leaves': 180, 'feature_fraction': 0.35925058551462635, 'bagging_fraction': 0.6346581995776897, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:36,896]\u001b[0m Trial 43 finished with value: 0.8456303972366149 and parameters: {'lambda_l1': 0.9583254889217268, 'lambda_l2': 0.11096357959404635, 'num_leaves': 208, 'feature_fraction': 0.3888743501401576, 'bagging_fraction': 0.6725271746573613, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 10:32:37,262]\u001b[0m Trial 44 finished with value: 0.8472193436960277 and parameters: {'lambda_l1': 1.0987407649558874, 'lambda_l2': 0.12773283520130593, 'num_leaves': 195, 'feature_fraction': 0.37576698332831054, 'bagging_fraction': 0.6500375753469138, 'bagging_freq': 2, 'min_child_samples': 87}. Best is trial 22 with value: 0.8543696027633851.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NT = 300\n",
    "\n",
    "for j in range(0,30):\n",
    "\n",
    "    for i in range(100,200):\n",
    "        r = random_integer = random.randint(42, 999)\n",
    "\n",
    "        try:\n",
    "            df_train = df_temp.loc[train_index_o.index]\n",
    "            df_train.head()\n",
    "            df_train = df_train.reset_index(drop = True)\n",
    "\n",
    "            df_train['ref_n_citation'] = df_train['ref_n_citation'].astype(float)\n",
    "            df_train['n_citation'] = df_train['n_citation'].astype(float)\n",
    "\n",
    "            df_train = df_train.loc[~df_train['cosine_similarity_y'].isna()]\n",
    "\n",
    "            #print(df_train['target'].value_counts())\n",
    "\n",
    "\n",
    "            df_train = df_train.dropna()\n",
    "\n",
    "            count_class_0, count_class_1 = df_train['target'].value_counts()\n",
    "\n",
    "            df_class_0 = df_train[df_train['target'] == 0]\n",
    "            df_class_1 = df_train[df_train['target'] == 1]\n",
    "\n",
    "            df_class_0_under = df_class_0.sample(int(count_class_1*1.3), random_state = r)\n",
    "            df_train_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "            df_train_under = df_train_under.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "            df_train = df_train_under.copy()\n",
    "\n",
    "            X = df_train.drop(['target','train_or_valid'], axis=1)  \n",
    "            y = df_train['target'] \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            blsmote = BorderlineSMOTE(random_state=42)\n",
    "            X_train_blsmote, y_train_blsmote = blsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "            print(\"Borderline-SMOTE resampled data shape:\", X_train_blsmote.shape, y_train_blsmote.shape)\n",
    "\n",
    "            break\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    X_train = X_train_blsmote\n",
    "    y_train = y_train_blsmote\n",
    "\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 0.7, 1.1),  \n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 0.09, 0.17),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 150, 350),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.35, 0.55),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.55, 0.7),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 2),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 80, 110)\n",
    "        }\n",
    "\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        model = lgb.train(\n",
    "            param, \n",
    "            train_data, \n",
    "            valid_sets=[test_data], \n",
    "            callbacks=[lgb.log_evaluation(period=200)] \n",
    "        )\n",
    "        y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        # AUC計算\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        return auc\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=NT)\n",
    "\n",
    "    best_lgbm_params = study.best_trial.params\n",
    "\n",
    "    # 最適化されたパラメータを出力\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    lgbm_clf = LGBMClassifier(**best_lgbm_params)\n",
    "\n",
    "    def cb_objective(trial):\n",
    "        param = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': False,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.04, 0.08), \n",
    "            'iterations': trial.suggest_int('iterations', 600, 750), \n",
    "            'depth': trial.suggest_int('depth', 5, 10), \n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2.0, 3.0), \n",
    "            'border_count': trial.suggest_int('border_count', 200, 300), \n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.7, 0.9) \n",
    "        }\n",
    "\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**param)\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50)\n",
    "\n",
    "        y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        return auc\n",
    "\n",
    "    cb_study = optuna.create_study(direction='maximize')\n",
    "    cb_study.optimize(cb_objective, n_trials=NT)\n",
    "\n",
    "    print(\"Best trial for CatBoost:\")\n",
    "    print(f\"  Value: {cb_study.best_trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in cb_study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "    best_cat_params = cb_study.best_trial.params\n",
    "    cat_clf = CatBoostClassifier(**best_cat_params)\n",
    "\n",
    "\n",
    "    lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lgbm_clf.predict(X_test)\n",
    "    y_pred_proba_lgbm = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cat_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = cat_clf.predict(X_test)\n",
    "    y_pred_proba_cat = cat_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_lgbm)\n",
    "    roc_auc_lgb = auc(fpr, tpr)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_cat)\n",
    "    roc_auc_cat = auc(fpr, tpr)\n",
    "\n",
    "    ensemble1 = (y_pred_proba_lgbm + y_pred_proba_cat) / 2\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, ensemble1)\n",
    "    roc_auc_ensemble1 = auc(fpr, tpr)\n",
    "\n",
    "    print(roc_auc_lgb,roc_auc_cat,roc_auc_ensemble1)\n",
    "\n",
    "    df_test = df_temp.loc[df['train_or_valid'] == 'test'].copy()\n",
    "\n",
    "    X_test = df_test.drop(['train_or_valid','target'], axis=1)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "    X_test = X_test[X.columns]\n",
    "\n",
    "    X_test.to_pickle(dir_path + 'X_test.pkl')\n",
    "    df_test.to_pickle(dir_path + 'df_test.pkl')\n",
    "    test_index_o.to_pickle(dir_path + 'test_index_o.pkl')\n",
    "\n",
    "    with open(dir_path + f\"lgbm_clf_{r}_{roc_auc_ensemble1*10000:.0f}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(lgbm_clf, file)\n",
    "\n",
    "    with open(dir_path + f\"cat_clf_{r}_{roc_auc_ensemble1*10000:.0f}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(cat_clf, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594436b-b9ac-4c58-bdeb-1b7233a7e93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89849850-358a-4281-9878-4496f1f67edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
