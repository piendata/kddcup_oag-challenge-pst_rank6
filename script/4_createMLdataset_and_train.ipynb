{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97257ad1-6ffa-4033-8071-eb34b32e3d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc  \n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE, KMeansSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import shap\n",
    "\n",
    "import pickle\n",
    "\n",
    "dir_path = '../data/PST/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9c1b18-e354-4bf9-888e-880a9ea83775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dir_path + 'dataset_v2.pkl')\n",
    "\n",
    "check = df.loc[(df['target'] == 1)\n",
    "               & (~df['ref_title'].isna())\n",
    "            & (df['citation_cnt'].isna())]\n",
    "\n",
    "tempolary_xml = pd.read_pickle(dir_path + 'tempolary_xml.pkl')\n",
    "tempolary_xml_ref = pd.read_pickle(dir_path + 'tempolary_xml.pkl')\n",
    "\n",
    "df = df.merge(tempolary_xml[['_id','title','abstract']],how = 'left',on = '_id')\n",
    "\n",
    "df['title'] = df.apply(lambda x: x['title_x'] if pd.notna(x['title_x']) else x['title_y'], axis=1)\n",
    "\n",
    "df.drop(columns=['title_x', 'title_y'], inplace=True)\n",
    "\n",
    "df['abstract'] = df.apply(lambda x: x['abstract_x'] if pd.notna(x['abstract_x']) else x['abstract_y'], axis=1)\n",
    "\n",
    "df.drop(columns=['abstract_x', 'abstract_y'], inplace=True)\n",
    "\n",
    "df['title'] = df['title'].str.replace('\\n', '', regex=False)\n",
    "df['ref_title'] = df['ref_title'].str.replace('\\n', '', regex=False)\n",
    "df['abstract'] = df['abstract'].str.replace('\\n', '', regex=False)\n",
    "df['ref_abstract'] = df['ref_abstract'].str.replace('\\n', '', regex=False)\n",
    "\n",
    "df['abstract'] = df['abstract'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['ref_abstract'] = df['ref_abstract'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['ref_title'] = df['ref_title'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['title'] = df['title'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "def set_flags(df, column, flags):\n",
    "    for flag, substr in flags.items():\n",
    "        df[flag] = np.where(df[column].str.contains(substr, case=False, na=False), 1, 0)\n",
    "\n",
    "flags = {\n",
    "    'IEEE_flg': 'ieee',\n",
    "    'acm_flg': 'acm',\n",
    "    'cvpr_flg': 'cvpr',\n",
    "    'nips_flg': 'nips',\n",
    "    'Econometrica_flg':'econometrica',\n",
    "    'KDD_flg':'kdd'\n",
    "}\n",
    "\n",
    "set_flags(df, 'venue', flags)\n",
    "set_flags(df, 'ref_venue', {f'ref_{k}': v for k, v in flags.items()})\n",
    "\n",
    "df['Section'] = df['Section'].fillna('')\n",
    "df['Pre Text'] = df['Pre Text'].fillna('')\n",
    "df['Post Text'] = df['Post Text'].fillna('')\n",
    "\n",
    "\n",
    "def set_text_flags(df, columns, patterns):\n",
    "    for col, flags in patterns.items():\n",
    "        for flag, substr in flags.items():\n",
    "            df[flag] = np.where(df[col].str.contains(substr, case=False, na=False), 1, 0)\n",
    "\n",
    "text_patterns = {\n",
    "    'Pre Text': {\n",
    "        'important_flg': 'important',\n",
    "        'motiva_flg': 'motiva',\n",
    "        'most_flg': ' most ',\n",
    "        'impact_flg': 'impact',\n",
    "        'based_flg': 'based'\n",
    "    },\n",
    "    'Post Text': {\n",
    "        'important_flg': 'important',\n",
    "        'motiva_flg': 'motiva',\n",
    "        'most_flg': ' most ',\n",
    "        'impact_flg': 'impact',\n",
    "        'based_flg': 'based'\n",
    "    },\n",
    "    'Section': {\n",
    "        'conclusion_flg': 'conclusion',\n",
    "        'intro_flg': 'intro',\n",
    "        'material_flg': 'material',\n",
    "        'method_flg': 'method',\n",
    "        'result_flg': 'result',\n",
    "        'discussion_flg': 'discussion',\n",
    "        'abstract_flg': 'abstract'\n",
    "    }\n",
    "}\n",
    "\n",
    "set_text_flags(df, text_patterns.keys(), text_patterns)\n",
    "\n",
    "\n",
    "valid_index_o = df.loc[df['train_or_valid'] == 'valid'][['_id','ref_title']].copy()\n",
    "test_index_o = df.loc[df['train_or_valid'] == 'test'][['_id','ref_title']].copy()\n",
    "\n",
    "venue_impact = pd.read_pickle(dir_path + 'venue_impact_v2.pkl')\n",
    "venue_impact.columns = ['venue','v_n_citation']\n",
    "\n",
    "dblp_feature = pd.read_pickle(dir_path + 'dblp_feature_v2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4ff6f-fe88-4b21-aae1-9362832bb820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b57bf31-d94f-4fef-a20c-3c2cf7992fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304353\n"
     ]
    }
   ],
   "source": [
    "node2vec = pd.read_csv(dir_path + 'node2vec_umap_v3.csv.gz',compression='gzip')\n",
    "#node2vec = pd.read_csv('./pst_node2vec_umap.csv.gz',compression='gzip')\n",
    "node2vec = node2vec[['UMAP1','UMAP2','node_id']].rename(columns = {'node_id':'_id'})\n",
    "df = df.merge(node2vec, on = '_id', how = 'left')\n",
    "node2vec = node2vec[['UMAP1','UMAP2','_id']].rename(columns = {'_id':'ref_id'})\n",
    "df = df.merge(node2vec, on = 'ref_id', how = 'left')\n",
    "\n",
    "author_citation = pd.read_pickle(dir_path + 'author_citation_v2.pkl')\n",
    "\n",
    "author_citation.columns = ['_id','author_citation']\n",
    "dblp_feature.columns = ['_id','in_citation_count','page_count']\n",
    "df = df.merge(author_citation,on = '_id',how = 'left')\n",
    "\n",
    "dblp_feature = dblp_feature.groupby('_id').sum().reset_index()\n",
    "\n",
    "#df = df.merge(co_author,on = ['_id','ref_id'],how = 'left')\n",
    "print(len(df))\n",
    "df = df.merge(dblp_feature,on = ['_id'],how = 'left')\n",
    "\n",
    "\n",
    "df.loc[df['Citation Number'] == 'Unknown', 'Citation Number'] = np.nan \n",
    "\n",
    "df['citation_cnt'] = df.groupby('_id')['citation_cnt'].transform(lambda x: x.fillna(x.median()))\n",
    "df['Citation Number'] = df.groupby('_id')['Citation Number'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "df.loc[df['Citation Number'] == 'Unknown','Citation Number'] = 99\n",
    "df['Citation Number'] = df['Citation Number'].fillna(99)\n",
    "df['Citation Number'] = df['Citation Number'].astype(int)\n",
    "df.loc[df['Citation Number'] >= 99,'Citation Number'] = 99\n",
    "df.loc[df['Citation Number'] < 1,'Citation Number'] = 99\n",
    "\n",
    "max_cinum = df[['Citation Number','_id']].loc[df['Citation Number'] != 999].groupby('_id').max().reset_index()\n",
    "max_cinum.columns = ['_id','max_citation_num']\n",
    "\n",
    "df = df.merge(max_cinum,how = 'left',on = '_id')\n",
    "\n",
    "df['Citation_Ration'] = df['Citation Number']/df['max_citation_num']\n",
    "\n",
    "train_index_o = pd.concat([df[(df['target'] == 1)],# & (df.annotation_ref.isna())],\n",
    "              df[(df['train_or_valid'] == 'train') & (df['target'] == 0)].sample(n = 7000,random_state= 42)])\n",
    "train_index_o.to_csv('train_index.csv',index = False)\n",
    "\n",
    "df['diff_year'] = df['year'] - df['ref_year']\n",
    "df['n_citation'] = df['n_citation'].apply(lambda x: x + 0.001)\n",
    "df['ref_n_citation'] = df['ref_n_citation'].apply(lambda x: x + 0.001)\n",
    "df['diff_year'] = df['diff_year'].apply(lambda x: x + 0.001)\n",
    "\n",
    "df.loc[df['diff_year'] <= 0, 'diff_year'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1d01fb-5db6-472a-a4c5-868f15d307db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304353\n",
      "304353\n",
      "304353\n"
     ]
    }
   ],
   "source": [
    "tsne_title = pd.read_pickle(dir_path + 'title_tsne_v2.pkl')\n",
    "tsne_abstract = pd.read_pickle(dir_path + 'abstract_tsne_v2.pkl')\n",
    "\n",
    "tsne_title = tsne_title.rename(columns = {'tsne_1':'tsne_1_title','tsne_2':'tsne_2_title'})\n",
    "tsne_abstract = tsne_abstract.rename(columns = {'tsne_1':'tsne_1_abstract','tsne_2':'tsne_2_abstract'})\n",
    "\n",
    "tsne_title = tsne_title.groupby(['_id','ref_title']).mean().reset_index()\n",
    "tsne_abstract = tsne_abstract.groupby(['_id','ref_title']).mean().reset_index()\n",
    "\n",
    "print(len(df))\n",
    "df = df.merge(tsne_title,on = ['_id','ref_title'],how = 'left')\n",
    "df = df.merge(tsne_abstract,on = ['_id','ref_title'],how = 'left')\n",
    "print(len(df))\n",
    "\n",
    "tsne_context = pd.read_pickle(dir_path + 'context_tsne.pkl')\n",
    "\n",
    "tsne_context = tsne_context.rename(columns = {'tsne_1':'tsne_1_context','tsne_2':'tsne_2_context'})\n",
    "tsne_context = tsne_context.drop(columns = {'Pre Text','Post Text'}).groupby(['_id','ref_title']).mean().reset_index()\n",
    "df = df.merge(tsne_context,on = ['_id','ref_title'],how = 'left')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ff4bdf-5925-4d7a-852f-e233862095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp = df[['citation_cnt', 'Citation Number',\n",
    "           'ref_n_citation', 'n_citation',\n",
    "           'train_or_valid', 'target',\n",
    "           'IEEE_flg', 'acm_flg', 'cvpr_flg', 'nips_flg',\n",
    "           'Econometrica_flg', 'KDD_flg', 'ref_IEEE_flg', 'ref_acm_flg',\n",
    "           'ref_cvpr_flg', 'ref_nips_flg', 'ref_Econometrica_flg', 'ref_KDD_flg',\n",
    "           'important_flg', 'motiva_flg', 'most_flg', 'impact_flg', 'based_flg',\n",
    "           'conclusion_flg', 'intro_flg', 'material_flg', 'method_flg',\n",
    "           'result_flg', 'discussion_flg', 'abstract_flg', \n",
    "            'UMAP1_x', 'UMAP2_x',\n",
    "              'UMAP1_y', 'UMAP2_y',\n",
    "           'author_citation',\n",
    "           'in_citation_count', 'page_count', 'max_citation_num',\n",
    "           'Citation_Ration', 'diff_year', 'tsne_2_title',\n",
    "           'tsne_ref_1_x', 'tsne_ref_2_x', 'cosine_similarity_x',\n",
    "           'mahalanobis_distance_x', 'tsne_1_abstract', 'tsne_2_abstract',\n",
    "           'tsne_ref_1_y', 'tsne_ref_2_y', 'cosine_similarity_y',\n",
    "           'mahalanobis_distance_y', 'tsne_1_context', 'tsne_2_context',\n",
    "           'tsne_ref_1', 'tsne_ref_2'\n",
    "             ]].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d5f07e-b9c1-40ea-accf-c0e0edd432e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-06-13 06:46:52,727]\u001b[0m A new study created in memory with name: no-name-51e040b3-e267-415a-ad31-f83513872607\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borderline-SMOTE resampled data shape: (1538, 53) (1538,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-06-13 06:46:56,573]\u001b[0m Trial 0 finished with value: 0.8197902097902099 and parameters: {'lambda_l1': 0.9044119130212096, 'lambda_l2': 0.11320933233080575, 'num_leaves': 206, 'feature_fraction': 0.4391167304160145, 'bagging_fraction': 0.6499302535922671, 'bagging_freq': 2, 'min_child_samples': 98}. Best is trial 0 with value: 0.8197902097902099.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 06:47:08,173]\u001b[0m Trial 1 finished with value: 0.826783216783217 and parameters: {'lambda_l1': 0.855828356694874, 'lambda_l2': 0.11341557978591345, 'num_leaves': 299, 'feature_fraction': 0.46904188925789153, 'bagging_fraction': 0.6142778660074084, 'bagging_freq': 1, 'min_child_samples': 90}. Best is trial 1 with value: 0.826783216783217.\u001b[0m\n",
      "\u001b[32m[I 2024-06-13 06:47:11,973]\u001b[0m Trial 2 finished with value: 0.8197902097902098 and parameters: {'lambda_l1': 0.8838111178984716, 'lambda_l2': 0.11853638064050996, 'num_leaves': 240, 'feature_fraction': 0.41487713037931984, 'bagging_fraction': 0.633592024644312, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 1 with value: 0.826783216783217.\u001b[0m\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NT = 400\n",
    "\n",
    "for j in range(0,20):\n",
    "\n",
    "    for i in range(100,200):\n",
    "        r = random_integer = random.randint(42, 999)\n",
    "\n",
    "        try:\n",
    "            df_train = df_temp.loc[train_index_o.index]\n",
    "            df_train.head()\n",
    "            df_train = df_train.reset_index(drop = True)\n",
    "\n",
    "            df_train['ref_n_citation'] = df_train['ref_n_citation'].astype(float)\n",
    "            df_train['n_citation'] = df_train['n_citation'].astype(float)\n",
    "\n",
    "            df_train = df_train.loc[~df_train['cosine_similarity_y'].isna()]\n",
    "\n",
    "            #print(df_train['target'].value_counts())\n",
    "\n",
    "\n",
    "            df_train = df_train.dropna()\n",
    "\n",
    "            count_class_0, count_class_1 = df_train['target'].value_counts()\n",
    "\n",
    "            df_class_0 = df_train[df_train['target'] == 0]\n",
    "            df_class_1 = df_train[df_train['target'] == 1]\n",
    "\n",
    "            df_class_0_under = df_class_0.sample(int(count_class_1*1.3), random_state = r)\n",
    "            df_train_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "            df_train_under = df_train_under.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "            df_train = df_train_under.copy()\n",
    "\n",
    "            X = df_train.drop(['target','train_or_valid'], axis=1)  \n",
    "            y = df_train['target'] \n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            blsmote = BorderlineSMOTE(random_state=42)\n",
    "            X_train_blsmote, y_train_blsmote = blsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "            print(\"Borderline-SMOTE resampled data shape:\", X_train_blsmote.shape, y_train_blsmote.shape)\n",
    "\n",
    "            break\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    X_train = X_train_blsmote\n",
    "    y_train = y_train_blsmote\n",
    "\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 0.8, 1.0),  \n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 0.1, 0.15),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 200, 300),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 0.5),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.65),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 2),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 90, 100)\n",
    "        }\n",
    "\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        model = lgb.train(\n",
    "            param, \n",
    "            train_data, \n",
    "            valid_sets=[test_data], \n",
    "            callbacks=[lgb.log_evaluation(period=200)] \n",
    "        )\n",
    "        y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        # AUC計算\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        return auc\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=NT)\n",
    "\n",
    "    best_lgbm_params = study.best_trial.params\n",
    "\n",
    "    # 最適化されたパラメータを出力\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    lgbm_clf = LGBMClassifier(**best_lgbm_params)\n",
    "\n",
    "    def cb_objective(trial):\n",
    "        param = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': False,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.07), \n",
    "            'iterations': trial.suggest_int('iterations', 650, 700), \n",
    "            'depth': trial.suggest_int('depth', 8, 10), \n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2.8, 3.0), \n",
    "            'border_count': trial.suggest_int('border_count', 240, 260), \n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.8, 0.85) \n",
    "        }\n",
    "\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**param)\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50)\n",
    "\n",
    "        y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        return auc\n",
    "\n",
    "    cb_study = optuna.create_study(direction='maximize')\n",
    "    cb_study.optimize(cb_objective, n_trials=NT)\n",
    "\n",
    "    print(\"Best trial for CatBoost:\")\n",
    "    print(f\"  Value: {cb_study.best_trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in cb_study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "    best_cat_params = cb_study.best_trial.params\n",
    "    cat_clf = CatBoostClassifier(**best_cat_params)\n",
    "\n",
    "\n",
    "    lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lgbm_clf.predict(X_test)\n",
    "    y_pred_proba_lgbm = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cat_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = cat_clf.predict(X_test)\n",
    "    y_pred_proba_cat = cat_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_lgbm)\n",
    "    roc_auc_lgb = auc(fpr, tpr)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_cat)\n",
    "    roc_auc_cat = auc(fpr, tpr)\n",
    "\n",
    "    ensemble1 = (y_pred_proba_lgbm + y_pred_proba_cat) / 2\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, ensemble1)\n",
    "    roc_auc_ensemble1 = auc(fpr, tpr)\n",
    "\n",
    "    print(roc_auc_lgb,roc_auc_cat,roc_auc_ensemble1)\n",
    "\n",
    "    df_test = df_temp.loc[df['train_or_valid'] == 'test'].copy()\n",
    "\n",
    "    X_test = df_test.drop(['train_or_valid','target'], axis=1)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "    X_test = X_test[X.columns]\n",
    "\n",
    "    X_test.to_pickle(dir_path + 'X_test.pkl')\n",
    "    df_test.to_pickle(dir_path + 'df_test.pkl')\n",
    "    test_index_o.to_pickle(dir_path + 'test_index_o.pkl')\n",
    "\n",
    "    with open(dir_path + f\"lgbm_clf_{r}_{roc_auc_ensemble1*10000:.0f}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(lgbm_clf, file)\n",
    "\n",
    "    with open(dir_path + f\"cat_clf_{r}_{roc_auc_ensemble1*10000:.0f}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(cat_clf, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594436b-b9ac-4c58-bdeb-1b7233a7e93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89849850-358a-4281-9878-4496f1f67edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
